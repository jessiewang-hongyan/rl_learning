{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36150df7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Last chapter we see how DQN works. This chapter we take a look at hwat could be done to improve DQN. We will introduce Double-DQN and Duel-DQN, with slight modification based on DQN and significant improvement on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1f888",
   "metadata": {},
   "source": [
    "# Double DQN\n",
    "The standard DQN is notoriously famous for its possible overestimation on $Q$. Why is so? The TD estimation of DQN is $r + \\gamma \\max_{a'} Q_{\\omega^-}(s', a')$. We can also write $\\max_{a'} Q_{\\omega^-}(s', a')$ as $$Q_{\\omega^-}(s', \\max_{a'} Q_{\\omega^-}(s', a')).$$ In other words, the $\\max$ operation here can be divided into 2 steps: 1. select the best action $s'$ under state $s$, and 2. calculate the corresponding value $Q_\\omega(s', a')$. Using the same Q-netowrk for the two calculation, each time we will get the maximum under current estimation. Since the network may have positive or negative bias, it is easy to see that the positive bias will be accumulated. For a large action space, such deficiency may break DQN totally. \n",
    "\n",
    "Motivative by this idea, Double-DQN solves the overestimation issue by use 2 networks for esitmation: $$Q_{\\omega^-}(s', \\max_{a'} Q_{\\omega}(s', a')),$$ where $Q_{\\omega^-}$ and $Q_{\\omega}$ are 2 different networks. By doing so, although $Q_{\\omega}$ may still overstimate every time, $Q_{\\omega^-}$ could have either positive or negative bias, which alleviates the overestimation. \n",
    "\n",
    "In traditional DQN, since we already have 2 Q-networks, we can directly use the training network for action selection, and the target network for value estimation. We can write out the optimization object directly:  $$ r + \\gamma  * Q_{\\omega^-}(s', \\max_{a'} Q_{\\omega}(s', a'))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a753bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
